{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0dc97d",
   "metadata": {},
   "source": [
    "# 00. Train Model\n",
    "\n",
    "Helper notebook for training fire risk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc091c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5185e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import json\n",
    "import aic_risk_modeling as arm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111002ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 54\n",
    "RNG = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d66b1",
   "metadata": {},
   "source": [
    "# Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d77f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCS Dir holding schema and tfrecords\n",
    "GCS_DATA_DIR = 'gs://aic-fire-amazon/results_2024_5k/'\n",
    "# glob match path for tfrecords\n",
    "TFRECORD_PATTERN = '*.tfrecord.gz'\n",
    "# Set patch size\n",
    "PATCH_SIZE = 128\n",
    "\n",
    "# For model, input and output bands\n",
    "INPUT_BANDS = (\n",
    "    ['{}{:02d}'.format('A', i) for i in range(64)]\n",
    "    + ['burned_area_2023']\n",
    ")\n",
    "OUTPUT_BANDS = ['BurnDate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da912eac",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pattern = os.path.join(GCS_DATA_DIR, 'training-{}'.format(TFRECORD_PATTERN))\n",
    "validation_pattern = os.path.join(GCS_DATA_DIR, 'validation-{}'.format(TFRECORD_PATTERN))\n",
    "\n",
    "schema = arm.train.infer_schema_from_gcs(GCS_DATA_DIR)\n",
    "feature_spec = arm.train.build_features_dict(schema, patch_size=PATCH_SIZE)\n",
    "\n",
    "print(\"Example features:\")\n",
    "for i, f in enumerate(list(feature_spec.keys())[:20]):\n",
    "    print(i + 1, f)\n",
    "\n",
    "training_ds = arm.train.dataset_from_gcs(training_pattern, feature_spec, \n",
    "                               input_bands=[k for k in feature_spec.keys() if k not in ['lat','lon','id']],\n",
    "                               output_bands=['BurnDate'],\n",
    "                               batch_size=8,\n",
    "                               shuffle_buffer=64)\n",
    "validation_ds = arm.train.dataset_from_gcs(validation_pattern, feature_spec, \n",
    "                               input_bands=[k for k in feature_spec.keys() if k not in ['lat','lon','id']],\n",
    "                               output_bands=['BurnDate'],\n",
    "                               batch_size=8,\n",
    "                               shuffle=False)\n",
    "for inputs, labels in training_ds.take(1):\n",
    "    print(\"Batch inputs keys:\", list(inputs.keys()))\n",
    "    print(\"Label shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = arm.train.get_mlp([PATCH_SIZE, PATCH_SIZE, len(INPUT_BANDS)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input dictionary layers.\n",
    "inputs_dict = {\n",
    "    name: tf.keras.Input(shape=(None, None, 1), name=name)\n",
    "    for name in INPUT_BANDS\n",
    "}\n",
    "\n",
    "concat = tf.keras.layers.Concatenate()(list(inputs_dict.values()))\n",
    "new_model = tf.keras.Model(inputs=inputs_dict, outputs=model(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025),\n",
    "    loss=\"Dice\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryIoU(target_class_ids=[1]),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "checkpoint_filepath = './checkpoint.model.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10)\n",
    "\n",
    "new_model.fit(\n",
    "    training_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=25,\n",
    "    callbacks=[model_checkpoint_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('checkpoint.model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_masks = np.array([b[1][i].numpy() for b in validation_ds for i in range(b[1].shape[0])])\n",
    "valid_burn_lastyear= np.array([b[0]['burned_area_2023'][i].numpy() for b in validation_ds for i in range(b[1].shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f86a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = new_model.predict(validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cdcc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f1_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))\n",
    "print(recall_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))\n",
    "print(precision_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))\n",
    "print(jaccard_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f1_score(valid_masks.flatten()>0.5, out.flatten()>0.99))\n",
    "print(recall_score(valid_masks.flatten()>0.5, out.flatten()>0.99))\n",
    "print(precision_score(valid_masks.flatten()>0.5, out.flatten()>0.99))\n",
    "print(jaccard_score(valid_masks.flatten()>0.5, out.flatten()>0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b84bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_risk_predict(input_batch, target_batch, output_i, batch_i, suptitle, cutoff=0.5):\n",
    "    fig, axs = plt.subplots(2,2)\n",
    "    fig.suptitle(suptitle)\n",
    "    # Embeddings\n",
    "    rgb = np.stack([\n",
    "        input_batch['A01'][batch_i].numpy(),\n",
    "        input_batch['A16'][batch_i].numpy(),\n",
    "        input_batch['A09'][batch_i].numpy()], axis=2)\n",
    "    # shift\n",
    "    vmin=-0.3\n",
    "    vmax=0.3\n",
    "    rgb = (rgb - vmin)/(vmax - vmin)\n",
    "    axs.flatten()[0].imshow(rgb)\n",
    "    axs.flatten()[0].set_title('Embeddings')\n",
    "\n",
    "    # 2022 burn\n",
    "    axs.flatten()[1].imshow(input_batch['burned_area_2023'][batch_i].numpy() > 0.5)\n",
    "    axs.flatten()[1].set_title('Burned area 2023')\n",
    "\n",
    "    # Prediction\n",
    "    axs.flatten()[2].imshow(output_i)\n",
    "    axs.flatten()[2].set_title('Predicted burned area 2024')\n",
    "\n",
    "    # 2023 burn (target)\n",
    "    axs.flatten()[3].imshow(target_batch[batch_i].numpy()>cutoff)\n",
    "    axs.flatten()[3].set_title('Actual burned area 2024')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for batch in validation_ds:\n",
    "    for i in range(batch[1].shape[0]):\n",
    "        if (batch[1][i].numpy()>0.5).sum()>0 or (out[j]>0.5).sum()>0:\n",
    "            visualize_risk_predict(\n",
    "                input_batch = batch[0],\n",
    "                target_batch = batch[1],\n",
    "                output_i = out[j],\n",
    "                batch_i=i,\n",
    "                suptitle='Image {}'.format(j),\n",
    "                cutoff=0.99\n",
    "            )\n",
    "        j+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
