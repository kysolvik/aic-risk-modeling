{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0dc97d",
   "metadata": {},
   "source": [
    "# Training data pipeline\n",
    "\n",
    "\n",
    "Most code borrowed from: https://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/Earth_Engine_training_patches_getPixels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5185e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import io\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import google\n",
    "from google.api_core import retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111002ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 54\n",
    "RNG = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc60085",
   "metadata": {},
   "source": [
    "# Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksolvik-misc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials, _ = google.auth.default()\n",
    "ee.Initialize(project=PROJECT, opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d66b1",
   "metadata": {},
   "source": [
    "# Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d77f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: ALPHAEARTH_EMBEDDINGS\n",
    "ALPHAEARTH_EMBEDDINGS = ee.ImageCollection('GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL')\n",
    "\n",
    "# The years from which to sample for alpha earth\n",
    "INPUT_YEAR = 2023\n",
    "\n",
    "# MB Fire annual burned area\n",
    "MB_FIRE = (ee.Image('projects/mapbiomas-public/assets/brazil/fire/collection4_1/mapbiomas_fire_collection41_annual_burned_v1')\n",
    "           .reduceResolution('mean', maxPixels=500))\n",
    "# MODIS burned area product\n",
    "MODIS_FIRE =  (ee.ImageCollection('MODIS/061/MCD64A1')\n",
    "               .select('BurnDate')\n",
    "              )\n",
    "FIRE_YEAR = 2024\n",
    "\n",
    "\n",
    "# Region of interest to sample from\n",
    "ROI = gpd.read_file('../data/Limites_RAISG_2025/Lim_Raisg.shp')\n",
    "\n",
    "# Number of areas to sample\n",
    "N_SAMPLE = 2000\n",
    "\n",
    "# Set final scale\n",
    "FINAL_SCALE = 500 # in Meters\n",
    "# Set patch size\n",
    "PATCH_SIZE = 128\n",
    "\n",
    "# How much to keep as validation\n",
    "VALIDATION_RATIO=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_points(roi: gpd.GeoDataFrame, n_sample: int, rng: np.random.Generator)->np.array:\n",
    "  \"\"\"Get random points within region of interest.\"\"\"\n",
    "  sample_df = roi.sample_points(n_sample, rng=rng).geometry.explode().get_coordinates()\n",
    "  sample_df.index = np.arange(sample_df.shape[0])\n",
    "  return sample_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27714441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precompute some inputs based on params\n",
    "# A random sample of N locations in the ROI as a list of GeoJSON points.\n",
    "SAMPLE_POINTS  = sample_random_points(ROI, N_SAMPLE, RNG)\n",
    "\n",
    "# Make a projection to discover the scale in degrees.\n",
    "PROJ_AE = ee.Projection('EPSG:4326').atScale(FINAL_SCALE)\n",
    "PROJ_AE_DICT = PROJ_AE.getInfo()\n",
    "# Get scales out of the transform.\n",
    "SCALE_X = PROJ_AE_DICT['transform'][0]\n",
    "SCALE_Y = -PROJ_AE_DICT['transform'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce6673",
   "metadata": {},
   "source": [
    "## Image retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4561550",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry.Retry()\n",
    "def compute_patch(coords, image, patch_size, scale_x, scale_y, band_sel=None):\n",
    "  \"\"\"Compute a patch of pixel, with upper-left corner defined by the coords.\"\"\"\n",
    "\n",
    "  # Make a request object.\n",
    "  request = {\n",
    "      'expression':image,\n",
    "      'fileFormat': 'NPY',\n",
    "      'grid': {\n",
    "          'dimensions': {\n",
    "              'width': patch_size,\n",
    "              'height':patch_size\n",
    "          },\n",
    "          'affineTransform': {\n",
    "              'scaleX': scale_x,\n",
    "              'shearX': 0,\n",
    "              'translateX': coords[0],\n",
    "              'shearY': 0,\n",
    "              'scaleY': scale_y,\n",
    "              'translateY': coords[1]\n",
    "          },\n",
    "          'crsCode': 'EPSG:4326',\n",
    "      },\n",
    "  }\n",
    "\n",
    "  if not band_sel is None:\n",
    "    request['bandIds'] = band_sel\n",
    "\n",
    "  return np.load(io.BytesIO(ee.data.computePixels(request)))\n",
    "\n",
    "def serialize_example(structured_array):\n",
    "  \"\"\"Convert structured numpy array to serliazed tf.Example proto\"\"\"\n",
    "  return array_to_example(structured_array).SerializeToString()\n",
    "\n",
    "def array_to_example(structured_array):\n",
    "  \"\"\"\"Convert structured numpy array to tf.Example proto.\"\"\"\n",
    "  feature = {}\n",
    "  for f in structured_array.dtype.names:\n",
    "    feature[f] = tf.train.Feature(\n",
    "        float_list = tf.train.FloatList(\n",
    "            value = structured_array[f].flatten()))\n",
    "  return tf.train.Example(\n",
    "      features = tf.train.Features(feature = feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeaf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = INPUT_YEAR\n",
    "ae_year_mean = (ALPHAEARTH_EMBEDDINGS\n",
    "            .filter(ee.Filter.calendarRange(year, year, 'year'))\n",
    "            .mosaic()\n",
    "            .setDefaultProjection(PROJ_AE)\n",
    "            .reduceResolution('mean', maxPixels=500)\n",
    "            )\n",
    "ae_prev_year_mean = (ALPHAEARTH_EMBEDDINGS\n",
    "            .filter(ee.Filter.calendarRange(year-1, year-1, 'year'))\n",
    "            .mosaic()\n",
    "            .setDefaultProjection(PROJ_AE)\n",
    "            .reduceResolution('mean', maxPixels=500)\n",
    "            )\n",
    "ae_prev_year_mean = ae_prev_year_mean.rename([b + '_prev_year' for b in ae_prev_year_mean.bandNames().getInfo()])\n",
    "\n",
    "mb_year = MB_FIRE\n",
    "\n",
    "modis_year = (MODIS_FIRE\n",
    "              .filter(ee.Filter.calendarRange(FIRE_YEAR,FIRE_YEAR, 'year'))\n",
    "              .min()\n",
    "              )\n",
    "\n",
    "joined_img = ae_year_mean.addBands(ae_prev_year_mean).addBands(mb_year).addBands(modis_year)\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "FEATURES = joined_img.bandNames().getInfo()\n",
    "KERNEL_SHAPE = [PATCH_SIZE, PATCH_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "with open('features_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(FEATURES_DICT, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d125f",
   "metadata": {},
   "source": [
    "# Beam pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2528b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEComputePatch(beam.DoFn):\n",
    "    def setup(self):\n",
    "        ee.Initialize(project=PROJECT, opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "\n",
    "    def process(self, coords, image, patch_size, scale_x, scale_y, band_sel=None):\n",
    "        \"\"\"Compute a patch of pixel, with upper-left corner defined by the coords.\"\"\"\n",
    "\n",
    "        # Make a request object.\n",
    "        request = {\n",
    "            'expression':image,\n",
    "            'fileFormat': 'NPY',\n",
    "            'grid': {\n",
    "                'dimensions': {\n",
    "                    'width': patch_size,\n",
    "                    'height':patch_size\n",
    "                },\n",
    "                'affineTransform': {\n",
    "                    'scaleX': scale_x,\n",
    "                    'shearX': 0,\n",
    "                    'translateX': coords[0],\n",
    "                    'shearY': 0,\n",
    "                    'scaleY': scale_y,\n",
    "                    'translateY': coords[1]\n",
    "                },\n",
    "                'crsCode': 'EPSG:4326',\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if not band_sel is None:\n",
    "            request['bandIds'] = band_sel\n",
    "\n",
    "        yield np.load(io.BytesIO(ee.data.computePixels(request)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(element, n_partitions) -> int:\n",
    "  weights = [1 - VALIDATION_RATIO, VALIDATION_RATIO]\n",
    "  return random.choices([0, 1], weights)[0]\n",
    "\n",
    "beam_options = PipelineOptions([], direct_num_workers=8, direct_running_mode='multi_processing')\n",
    "\n",
    "with beam.Pipeline(options=beam_options) as pipeline:\n",
    "  training_data, validation_data = (\n",
    "      pipeline\n",
    "      | 'Create points' >> beam.Create(SAMPLE_POINTS)\n",
    "      | 'Get patch' >> beam.ParDo(EEComputePatch(), joined_img, PATCH_SIZE, SCALE_X, SCALE_Y)\n",
    "      | 'Serialize' >> beam.Map(serialize_example)\n",
    "      | 'Split dataset' >> beam.Partition(split_dataset, 2)\n",
    "  )\n",
    "\n",
    "  training_data | 'Write training data' >> beam.io.WriteToTFRecord(\n",
    "      '../data/beamMODIS/training', file_name_suffix='.tfrecord.gz'\n",
    "  )\n",
    "  validation_data | 'Write validation data' >> beam.io.WriteToTFRecord(\n",
    "      '../data/beamMODIS/validation', file_name_suffix='.tfrecord.gz'\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
