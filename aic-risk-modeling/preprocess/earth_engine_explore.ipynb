{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0dc97d",
   "metadata": {},
   "source": [
    "# Earth Engine Explore\n",
    "\n",
    "Explore possible explanatory and response variables for fire risk modeling across the Amazon\n",
    "\n",
    "\n",
    "Most code borrowed from: https://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/Earth_Engine_training_patches_getPixels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5185e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import concurrent\n",
    "import ee\n",
    "import google\n",
    "import io\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from google.api_core import retry\n",
    "from google.protobuf import json_format\n",
    "from IPython.display import Image\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111002ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 54\n",
    "RNG = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc60085",
   "metadata": {},
   "source": [
    "# Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ksolvik-misc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials, _ = google.auth.default()\n",
    "ee.Initialize(project=PROJECT)#, opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d77f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE WITH YOUR BUCKET!\n",
    "OUTPUT_FILE = '../data/test.tfrecord.gz'\n",
    "\n",
    "# MODIS vegetation indices, 16-day.\n",
    "ALPHAEARTH_EMBEDDINGS = ee.ImageCollection('GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL')\n",
    "# Bay area.\n",
    "ROI = gpd.read_file('../data/Limites_RAISG_2025/Lim_Raisg.shp')\n",
    "# ROI = ee.Geometry.Rectangle(\n",
    "#     [-123.05832753906247, 37.03109527141115,\n",
    "#      -121.14121328124997, 38.24468432993584])\n",
    "\n",
    "# Number of areas to sample\n",
    "N_SAMPLE = 5\n",
    "\n",
    "# A random sample of N locations in the ROI as a list of GeoJSON points.\n",
    "SAMPLE = ROI.sample_points(N_SAMPLE, rng=RNG).geometry.explode().get_coordinates()\n",
    "SAMPLE.index = np.arange(SAMPLE.shape[0])\n",
    "\n",
    "# The years from which to sample\n",
    "YEARS = np.arange(2023, 2024)\n",
    "\n",
    "# Make a projection to discover the scale in degrees.\n",
    "SCALE_AE = 10\n",
    "PROJ_AE = ee.Projection('EPSG:4326').atScale(SCALE_AE)\n",
    "PROJ_AE_DICT = PROJ_AE.getInfo()\n",
    "# Get scales out of the transform.\n",
    "SCALE_X = PROJ_AE_DICT['transform'][0]\n",
    "SCALE_Y = -PROJ_AE_DICT['transform'][4]\n",
    "# Set patch size\n",
    "PATCH_SIZE = 256\n",
    "\n",
    "\n",
    "MB_FIRE = ee.Image('projects/mapbiomas-public/assets/brazil/fire/collection4_1/mapbiomas_fire_collection41_annual_burned_v1')\n",
    "MB_FIRE_REPROJ = MB_FIRE.reproject(PROJ_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce6673",
   "metadata": {},
   "source": [
    "## Image retrieval functions\n",
    "\n",
    "This section has a function to get a 1000x1000 meter patch of pixels from an asset, centered on the provided coordinates, as a numpy array.  The function can be retried automatically by using the [Retry](https://googleapis.dev/python/google-api-core/latest/retry.html) decorator.  There is also a function to serialize a structured array to a `tf.Example` proto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4561550",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry.Retry()\n",
    "def get_patch(coords, ic, patch_size, scale_x, scale_y, band_sel=None, filter_point=True):\n",
    "  \"\"\"Get a patch of pixels from an asset, centered on the coords.\"\"\"\n",
    "  ee_point = ee.Geometry.Point(coords)\n",
    "  if filter_point:\n",
    "    image = (ic\n",
    "        .filterBounds(ee_point)\n",
    "        .first())\n",
    "  else:\n",
    "    image = (ic\n",
    "        .first())\n",
    "  image_id = image.getInfo()['id']\n",
    "\n",
    "  # Make a request object.\n",
    "  request = {\n",
    "      'assetId': image_id,\n",
    "      'fileFormat': 'NPY',\n",
    "      'grid': {\n",
    "          'dimensions': {\n",
    "              'width': patch_size,\n",
    "              'height':patch_size\n",
    "          },\n",
    "          'affineTransform': {\n",
    "              'scaleX': scale_x,\n",
    "              'shearX': 0,\n",
    "              'translateX': coords[0],\n",
    "              'shearY': 0,\n",
    "              'scaleY': scale_y,\n",
    "              'translateY': coords[1]\n",
    "          },\n",
    "          'crsCode': 'EPSG:4326',\n",
    "      },\n",
    "  }\n",
    "\n",
    "  if not band_sel is None:\n",
    "    request['bandIds'] = band_sel\n",
    "\n",
    "  return np.load(io.BytesIO(ee.data.getPixels(request)))\n",
    "\n",
    "@retry.Retry()\n",
    "def compute_patch(coords, image, patch_size, scale_x, scale_y, band_sel=None):\n",
    "  \"\"\"Compute a patch of pixel, with upper-left corner defined by the coords.\"\"\"\n",
    "\n",
    "  # Make a request object.\n",
    "  request = {\n",
    "      # 'assetId': image_id,\n",
    "      'expression':image,\n",
    "      'fileFormat': 'NPY',\n",
    "      'grid': {\n",
    "          'dimensions': {\n",
    "              'width': patch_size,\n",
    "              'height':patch_size\n",
    "          },\n",
    "          'affineTransform': {\n",
    "              'scaleX': scale_x,\n",
    "              'shearX': 0,\n",
    "              'translateX': coords[0],\n",
    "              'shearY': 0,\n",
    "              'scaleY': scale_y,\n",
    "              'translateY': coords[1]\n",
    "          },\n",
    "          'crsCode': 'EPSG:4326',\n",
    "      },\n",
    "  }\n",
    "\n",
    "  if not band_sel is None:\n",
    "    request['bandIds'] = band_sel\n",
    "\n",
    "  return np.load(io.BytesIO(ee.data.computePixels(request)))\n",
    "\n",
    "def _float_feature(floats):\n",
    "  \"\"\"Returns a float_list from a float list.\"\"\"\n",
    "  print(floats)\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=floats))\n",
    "\n",
    "\n",
    "def array_to_example(structured_array):\n",
    "  \"\"\"\"Serialize a structured numpy array into a tf.Example proto.\"\"\"\n",
    "  feature = {}\n",
    "  for f in structured_array.dtype.names:\n",
    "    feature[f] = tf.train.Feature(\n",
    "        float_list = tf.train.FloatList(\n",
    "            value = structured_array[f].flatten()))\n",
    "  return tf.train.Example(\n",
    "      features = tf.train.Features(feature = feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeaf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=10)\n",
    "\n",
    "writer = tf.io.TFRecordWriter(OUTPUT_FILE, 'GZIP')\n",
    "\n",
    "for year in tqdm(YEARS):\n",
    "    year = int(year)\n",
    "    ae_year = ALPHAEARTH_EMBEDDINGS.filter(\n",
    "        ee.Filter.calendarRange(year, year, 'year')\n",
    "    ).mosaic()\n",
    "    mb_year = MB_FIRE_REPROJ\n",
    "\n",
    "    joined_img = ae_year.addBands(mb_year)\n",
    "\n",
    "    future_to_image = {\n",
    "        executor.submit(compute_patch, [point.x, point.y], joined_img, PATCH_SIZE, SCALE_X, SCALE_Y):\n",
    "            'ALL_{}'.format(index) for index, point in SAMPLE.iterrows()\n",
    "    }\n",
    "\n",
    "    arrays = ()\n",
    "    types = []\n",
    "    for future in concurrent.futures.as_completed(future_to_image):\n",
    "      image_id = future_to_image[future]\n",
    "      try:\n",
    "          np_array = future.result()\n",
    "          example_proto = array_to_example(np_array)\n",
    "          writer.write(example_proto.SerializeToString())\n",
    "          writer.flush()\n",
    "      except Exception as e:\n",
    "          print(e)\n",
    "          pass\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the size and shape of patches expected by the model.\n",
    "FEATURES = joined_img.bandNames().getInfo()\n",
    "KERNEL_SHAPE = [PATCH_SIZE, PATCH_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"Parse a serialized example.\"\"\"\n",
    "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(OUTPUT_FILE, compression_type='GZIP')\n",
    "dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85707834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "  rgb = np.stack([\n",
    "      data['A00'].numpy(),\n",
    "      data['A01'].numpy(),\n",
    "      data['A02'].numpy()], axis=2)\n",
    "  plt.imshow(rgb)\n",
    "  plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
