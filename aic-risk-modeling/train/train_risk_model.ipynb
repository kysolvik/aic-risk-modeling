{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0dc97d",
   "metadata": {},
   "source": [
    "# Earth Engine Explore\n",
    "\n",
    "Explore possible explanatory and response variables for fire risk modeling across the Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5185e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111002ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 54\n",
    "RNG = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d66b1",
   "metadata": {},
   "source": [
    "# Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d77f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final scale\n",
    "FINAL_SCALE = 500 # in Meters\n",
    "# Set patch size\n",
    "PATCH_SIZE = 128\n",
    "\n",
    "# For model, input and output bands\n",
    "INPUT_BANDS = (\n",
    "    ['{}{:02d}'.format('A', i) for i in range(64)]\n",
    "    + ['burned_area_2023']\n",
    "    # + ['{}{:02d}_prev_year'.format('A', i) for i in range(64)]\n",
    "    # + ['burned_area_{}'.format(y) for y in range(1985, 2024)]\n",
    ")\n",
    "# INPUT_BANDS = ['burned_area_{}'.format(y) for y in range(1985, 2024)]\n",
    "OUTPUT_BANDS = ['BurnDate']\n",
    "\n",
    "# Structure needed for parsing tensorflow record\n",
    "with open('features_dict.pkl', 'rb') as f:\n",
    "    FEATURES_DICT = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da912eac",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augment(tf.keras.layers.Layer):\n",
    "  def __init__(self, seed=42):\n",
    "    super().__init__()\n",
    "    # both use the same seed, so they'll make the same random changes.\n",
    "    self.augment_inputs = tf.keras.layers.RandomFlip(\n",
    "        mode=\"horizontal_and_vertical\", seed=seed)\n",
    "    self.augment_labels = tf.keras.layers.RandomFlip(\n",
    "        mode=\"horizontal_and_vertical\", seed=seed)\n",
    "\n",
    "  def call(self, inputs, labels):\n",
    "    inputs = {name: self.augment_inputs(v) for name, v in inputs.items()}\n",
    "    labels = self.augment_labels(labels)\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "def to_tuple(inputs):\n",
    "  return (\n",
    "      {name: inputs[name] for name in INPUT_BANDS},\n",
    "      inputs[OUTPUT_BANDS[0]] > 0\n",
    "      # tf.one_hot(tf.cast(inputs[OUTPUT_BANDS[0]], tf.uint8), )\n",
    "  )\n",
    "\n",
    "\n",
    "def get_dataset(pattern, batch_size, shuffle=True):\n",
    "  dataset = tf.data.Dataset.list_files(pattern).interleave(\n",
    "      lambda filename: tf.data.TFRecordDataset(filename, compression_type='GZIP'))\n",
    "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  dataset = dataset.map(to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  dataset = dataset.cache()\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(512)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "# Create the training and validation datasets.\n",
    "training_dataset = get_dataset('../data/beam/training-*.tfrecord.gz', 8) #.map(Augment(), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_dataset = get_dataset('../data/beam/validation-*.tfrecord.gz', 1, shuffle=False)\n",
    "\n",
    "# Inspect the first element from the training dataset.\n",
    "for inputs, outputs in training_dataset.take(1):\n",
    "  print(\"inputs:\")\n",
    "  for name, values in inputs.items():\n",
    "    print(f\"  {name}: {values.dtype.name} {values.shape}\")\n",
    "  print(f\"outputs: {outputs.dtype.name} {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_shape):\n",
    "    inputs = keras.Input(shape=[None, None, len(INPUT_BANDS)])\n",
    "\n",
    "    # --- Encoder ---\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    b = conv_block(p4, 1024)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    d1 = decoder_block(b, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    # --- Output layer ---\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    return keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = layers.SeparableConv2D(num_filters, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.SeparableConv2D(num_filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = layers.MaxPooling2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.concatenate([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_unet_lite(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # --- Encoder (shallow + fewer filters) ---\n",
    "    s1, p1 = encoder_block(inputs, 32)\n",
    "    s2, p2 = encoder_block(p1, 64)\n",
    "    s3, p3 = encoder_block(p2, 128)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    b = conv_block(p3, 256)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    d1 = decoder_block(b, s3, 128)\n",
    "    d2 = decoder_block(d1, s2, 64)\n",
    "    d3 = decoder_block(d2, s1, 32)\n",
    "\n",
    "    # --- Output ---\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d3)\n",
    "\n",
    "    return keras.Model(inputs, outputs, name=\"U-Net-Lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b78ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    inputs = keras.Input(shape=[None, None, len(INPUT_BANDS)])\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for filters in [64, 128]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_mlp(input_shape):\n",
    "    inputs = keras.Input(shape=[None, None, len(INPUT_BANDS)])\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    # x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_multi_scale_mlp_head(input_shape, hidden=128):\n",
    "    inputs = keras.Input(shape=[None, None, len(INPUT_BANDS)])\n",
    "\n",
    "    # --- scale 1 (original resolution) ---\n",
    "    s1 = layers.Dense(hidden, activation=\"gelu\")(inputs)\n",
    "\n",
    "    # --- scale 2 (128x128) ---\n",
    "    s2 = layers.AveragePooling2D(pool_size=2)(inputs)\n",
    "    s2 = layers.Dense(hidden, activation=\"gelu\")(s2)\n",
    "    s2 = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(s2)\n",
    "\n",
    "    # --- scale 3 (64x64) ---\n",
    "    s3 = layers.AveragePooling2D(pool_size=4)(inputs)\n",
    "    s3 = layers.Dense(hidden, activation=\"gelu\")(s3)\n",
    "    s3 = layers.UpSampling2D(size=4, interpolation=\"bilinear\")(s3)\n",
    "\n",
    "    # Fuse\n",
    "    fused = layers.Concatenate()([s1, s2, s3])\n",
    "    fused = layers.LayerNormalization()(fused)\n",
    "    fused = layers.Dense(hidden, activation=\"gelu\")(fused)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(fused)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mlp([PATCH_SIZE, PATCH_SIZE, len(INPUT_BANDS)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input dictionary layers.\n",
    "inputs_dict = {\n",
    "    name: tf.keras.Input(shape=(None, None, 1), name=name)\n",
    "    for name in INPUT_BANDS\n",
    "}\n",
    "\n",
    "concat = tf.keras.layers.Concatenate()(list(inputs_dict.values()))\n",
    "new_model = tf.keras.Model(inputs=inputs_dict, outputs=model(concat))\n",
    "# print(new_model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025),\n",
    "    loss=\"Dice\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryIoU(target_class_ids=[1]),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "checkpoint_filepath = './checkpoint.model.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10)\n",
    "\n",
    "new_model.fit(\n",
    "    training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=25,\n",
    "    callbacks=[model_checkpoint_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('checkpoint.model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_masks = np.array([b[1][i].numpy() for b in validation_dataset for i in range(b[1].shape[0])])\n",
    "valid_burn_lastyear= np.array([b[0]['burned_area_2023'][i].numpy() for b in validation_dataset for i in range(b[1].shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f86a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = new_model.predict(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cdcc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f1_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))\n",
    "print(recall_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))\n",
    "print(precision_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))\n",
    "print(jaccard_score(valid_masks.flatten()>0.5, valid_burn_lastyear.flatten()>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f1_score(valid_masks.flatten()>0.5, out.flatten()>0.99))\n",
    "print(recall_score(valid_masks.flatten()>0.5, out.flatten()>0.99))\n",
    "print(precision_score(valid_masks.flatten()>0.5, out.flatten()>0.99))\n",
    "print(jaccard_score(valid_masks.flatten()>0.5, out.flatten()>0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b84bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_risk_predict(input_batch, target_batch, output_i, batch_i, suptitle, cutoff=0.5):\n",
    "    fig, axs = plt.subplots(2,2)\n",
    "    fig.suptitle(suptitle)\n",
    "    # Embeddings\n",
    "    rgb = np.stack([\n",
    "        input_batch['A01'][batch_i].numpy(),\n",
    "        input_batch['A16'][batch_i].numpy(),\n",
    "        input_batch['A09'][batch_i].numpy()], axis=2)\n",
    "    # shift\n",
    "    vmin=-0.3\n",
    "    vmax=0.3\n",
    "    rgb = (rgb - vmin)/(vmax - vmin)\n",
    "    axs.flatten()[0].imshow(rgb)\n",
    "    axs.flatten()[0].set_title('Embeddings')\n",
    "\n",
    "    # 2022 burn\n",
    "    axs.flatten()[1].imshow(input_batch['burned_area_2023'][batch_i].numpy() > 0.5)\n",
    "    axs.flatten()[1].set_title('Burned area 2023')\n",
    "\n",
    "    # Prediction\n",
    "    axs.flatten()[2].imshow(output_i)\n",
    "    axs.flatten()[2].set_title('Predicted burned area 2024')\n",
    "\n",
    "    # 2023 burn (target)\n",
    "    axs.flatten()[3].imshow(target_batch[batch_i].numpy()>cutoff)\n",
    "    axs.flatten()[3].set_title('Actual burned area 2024')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for batch in validation_dataset:\n",
    "    for i in range(batch[1].shape[0]):\n",
    "        if (batch[1][i].numpy()>0.5).sum()>0 or (out[j]>0.5).sum()>0:\n",
    "            visualize_risk_predict(\n",
    "                input_batch = batch[0],\n",
    "                target_batch = batch[1],\n",
    "                output_i = out[j],\n",
    "                batch_i=i,\n",
    "                suptitle='Image {}'.format(j),\n",
    "                cutoff=0.99\n",
    "            )\n",
    "        j+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
